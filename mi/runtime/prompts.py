from __future__ import annotations

import json
from typing import Any


def _to_json(obj: Any) -> str:
    return json.dumps(obj, indent=2, sort_keys=True)


def compile_values_prompt(*, values_text: str) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Compile user values/preferences into a compact structured summary (V1).",
            "",
            "Hard constraints (must respect in your decision procedure):",
            "- MI sits above Hands (execution agent; V1 default: Codex CLI) and only controls input + reads output.",
            "- MI does NOT intercept or gate Hands tool execution.",
            "- MI does NOT force Hands into step-by-step protocols.",
            "- Refactor intent is behavior-preserving by default unless explicitly requested otherwise.",
            "- If a project has no tests, MI asks once per project for a testless verification strategy, then remembers it.",
            "- MI does not ask for 'completion confirmation' by default; MI self-evaluates done/blocked.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no code fences, no extra keys, no extra commentary.",
            "- Keep values_summary short (5-12 bullets).",
            "- decision_procedure.mermaid MUST be a valid Mermaid flowchart (flowchart TD ...).",
            "",
            "User values/preferences text (verbatim):",
            values_text.strip(),
            "",
            "Now output the compiled values JSON.",
        ]
    ).strip() + "\n"


def values_claim_patch_prompt(
    *,
    values_text: str,
    compiled_values: dict[str, Any],
    existing_values_claims: list[dict[str, Any]],
    allowed_event_ids: list[str],
    allowed_retract_claim_ids: list[str],
    notes: str,
) -> str:
    """Build a prompt that migrates/updates user values into Thought DB preference/goal claims.

    Output must follow `schemas/values_claim_patch.json`.
    """

    allowed = [str(x) for x in (allowed_event_ids or []) if str(x).strip()][:40]
    retractable = [str(x) for x in (allowed_retract_claim_ids or []) if str(x).strip()][:400]
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Update the user's global values/preferences as reusable atomic Claims in the Thought DB.",
            "",
            "Goal:",
            "- Produce a SMALL patch that evolves existing value claims into the new set implied by values_text.",
            "- Use supersedes/same_as edges to preserve history and avoid broken references.",
            "",
            "Hard constraints:",
            "- Only use the provided values_text and existing_values_claims as input (do not invent).",
            "- Every NEW claim MUST cite 1-5 EvidenceLog event_id(s) from the allowed list.",
            "- Every edge MUST cite 1-5 EvidenceLog event_id(s) from the allowed list.",
            "- Prefer claim_type=preference or goal for values. Avoid fact/assumption unless truly needed.",
            "- New value claims MUST be scope=global and visibility=global.",
            "- Include the stable tag 'values:base' on every NEW value claim.",
            "- Also include a tag 'values_set:<event_id>' for traceability.",
            "- Keep the patch minimal: only create new claims when needed; reuse existing claims via same_as when equivalent.",
            "- To update a claim's meaning/text, create a NEW claim and add supersedes(old_claim_id -> new_local_id).",
            "",
            "Retractions:",
            "- If an existing value claim is clearly removed or invalidated by the new values_text, add its claim_id to retract_claim_ids.",
            "- You may ONLY retract claim_ids from the provided allowed_retract_claim_ids list.",
            "- Be conservative: prefer supersedes over retract when it is a refinement rather than a full removal.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- local_id values MUST be unique (e.g., c1, c2). Edges may reference existing claim_id or local_id.",
            "",
            "values_text (verbatim):",
            (values_text or "").strip(),
            "",
            "compiled_values (structured, best-effort; may be empty):",
            _to_json(compiled_values if isinstance(compiled_values, dict) else {}),
            "",
            "existing_values_claims (active canonical, compact):",
            _to_json(existing_values_claims if isinstance(existing_values_claims, list) else []),
            "",
            "Allowed EvidenceLog event_id list (MUST cite only from here):",
            _to_json(allowed),
            "",
            "allowed_retract_claim_ids:",
            _to_json(retractable),
            "",
            "Run notes:",
            (notes or "").strip(),
            "",
            "Now output the values claim patch JSON.",
        ]
    ).strip() + "\n"


def extract_evidence_prompt(
    *,
    task: str,
    hands_provider: str,
    light_injection: str,
    batch_input: str,
    hands_batch_summary: dict[str, Any],
    repo_observation: dict[str, Any],
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Extract durable evidence from a Hands batch run.",
            "",
            "Rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- Be concise: keep strings short and factual.",
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "MI light injection (what Hands was told):",
            light_injection.strip(),
            "",
            "Batch input sent to Hands (verbatim):",
            (batch_input or "").strip(),
            "",
            "User task:",
            task.strip(),
            "",
            "Hands batch summary (machine extracted):",
            _to_json(hands_batch_summary),
            "",
            "Repo observation (read-only heuristic):",
            _to_json(repo_observation),
            "",
        ]
    ).strip() + "\n"


def decide_next_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    active_workflow: dict[str, Any] | None = None,
    workflow_run: dict[str, Any] | None = None,
    recent_evidence: list[dict[str, Any]],
    hands_last_message: str,
    repo_observation: dict[str, Any],
    check_plan: dict[str, Any],
    auto_answer: dict[str, Any],
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation), operating above Hands.",
            "Decide what to do next after a Hands batch, minimizing user burden.",
            "",
            "Constraints:",
            "- This prompt also serves as MI's 'closure' evaluation: if the task is complete, stop.",
            "- Only set status=done when confidence >= 0.6; otherwise keep working or run checks.",
            "- If status=done: set next_action=stop.",
            "- If status=blocked: set next_action=ask_user and provide ask_user_question.",
            "- Do NOT ask the user to 'confirm completion' as a default. MI self-evaluates done/blocked.",
            "- Ask the user ONLY when MI cannot proceed safely due to missing information or value conflicts.",
            "- If the project has no tests and verification is needed, ask the user ONCE per project for a testless verification strategy, then remember it (ProjectOverlay).",
            "- Prefer sending a next instruction to Hands over asking the user, when values/evidence allow.",
            "- Canonical values/preferences are provided via Thought DB context (especially values_claims); treat it as canonical when deciding.",
            "- If a minimal check plan is provided and should_run_checks=true, prefer sending hands_check_input to Hands before further work, unless user input is required first.",
            "- If needs_testless_strategy=true: first look for a canonical preference Claim in Thought DB context tagged 'mi:testless_verification_strategy'. If none exists, ask the user using testless_strategy_question.",
            "- If an auto-answer suggestion is provided and should_answer=true, prefer sending hands_answer_input to Hands (possibly combined with hands_check_input) instead of asking the user.",
            "- If auto_answer.needs_user_input=true, prefer asking the user using auto_answer.ask_user_question, unless you can safely answer from values/evidence already available (then send_to_hands).",
            "- If check_plan.should_run_checks=false but verification seems necessary, you may still propose a small set of checks via next_hands_input.",
            "",
            "Output:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (deterministic retrieval; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Active workflow (if any; MI IR):",
            _to_json(active_workflow if isinstance(active_workflow, dict) else {}),
            "",
            "Workflow run state (best-effort cursor; if any):",
            _to_json(workflow_run if isinstance(workflow_run, dict) else {}),
            "",
            "Repo observation (read-only heuristic):",
            _to_json(repo_observation),
            "",
            "Minimal check plan (from plan_min_checks):",
            _to_json(check_plan),
            "",
            "Auto-answer suggestion (from auto_answer_to_hands):",
            _to_json(auto_answer),
            "",
            "Recent evidence (most recent last):",
            _to_json(recent_evidence),
            "",
            "Hands last message (raw):",
            hands_last_message.strip(),
            "",
            "Now decide the next action.",
        ]
    ).strip() + "\n"


def loop_break_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    recent_evidence: list[dict[str, Any]],
    repo_observation: dict[str, Any],
    loop_pattern: str,
    loop_reason: str,
    hands_last_message: str,
    planned_next_input: str,
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation), operating above Hands.",
            "MI detected a repeated stuck loop while trying to send the next instruction to Hands.",
            "",
            "Goal:",
            "- Break the loop with minimal user burden and minimal disruption to Hands autonomy.",
            "- Prefer a small rewrite of the next instruction to make progress or reduce uncertainty.",
            "",
            "Constraints:",
            "- MI only controls prompt input and reads output; MI does NOT intercept tools/commands.",
            "- Do NOT enforce rigid step-by-step protocols on Hands.",
            "- Do NOT ask the user by default. Only choose action=ask_user when truly blocked on missing info or value conflict.",
            "- If you choose action=run_checks_then_continue: provide a short check_intent; MI will plan checks separately.",
            "- If you choose action=rewrite_next_input: provide rewritten_next_input that is meaningfully different and likely to make progress.",
            "- You may choose stop_done only when evidence strongly implies task completion.",
            "- You may choose stop_blocked when MI cannot proceed safely without user input or external changes.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- Always include: action, confidence, rewritten_next_input, check_intent, ask_user_question, notes.",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (canonical values/preferences; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Repo observation (read-only heuristic):",
            _to_json(repo_observation),
            "",
            "Recent evidence (most recent last):",
            _to_json(recent_evidence),
            "",
            f"Loop pattern: {str(loop_pattern or '').strip()}",
            f"Loop reason: {str(loop_reason or '').strip()}",
            "",
            "Hands last message (raw):",
            (hands_last_message or "").strip(),
            "",
            "Planned next input to Hands (verbatim):",
            (planned_next_input or "").strip(),
            "",
            "Now output the loop break JSON.",
        ]
    ).strip() + "\n"


def risk_judge_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    risk_signals: list[str],
    hands_last_message: str,
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Assess risk for a Hands batch using user values/preferences and evidence.",
            "",
            "Rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- If information is insufficient, set severity to 'medium' and should_ask_user=true.",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (canonical values/preferences; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Detected risk signals (heuristic, may be empty):",
            _to_json(risk_signals),
            "",
            "Hands last message (raw):",
            hands_last_message.strip(),
            "",
            "Now output the risk judgement.",
        ]
    ).strip() + "\n"


def plan_min_checks_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    recent_evidence: list[dict[str, Any]],
    repo_observation: dict[str, Any],
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Plan minimal, high-information verification checks to reduce uncertainty.",
            "",
            "Constraints:",
            "- MI does NOT run checks directly; Hands should execute checks when instructed.",
            "- Prefer existing project checks (tests/build/lint/typecheck) over introducing new tooling.",
            "- You may suggest generating a minimal smoke test only when it is low-cost and aligned with values.",
            "- If the project has no tests and verification is needed: first look for a canonical preference Claim in Thought DB context tagged 'mi:testless_verification_strategy'. If present, use it and set needs_testless_strategy=false. Otherwise, set needs_testless_strategy=true and ask the user ONCE per project for a testless verification strategy.",
            "- Do NOT ask the user to confirm completion; only ask when blocked by missing info.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- If no checks are needed, set should_run_checks=false and hands_check_input=\"\".",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (canonical values/preferences; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Repo observation (read-only heuristic):",
            _to_json(repo_observation),
            "",
            "Recent evidence (most recent last):",
            _to_json(recent_evidence),
            "",
            "Now plan the minimal checks and produce a Hands instruction if needed.",
        ]
    ).strip() + "\n"


def workflow_progress_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    workflow: dict[str, Any],
    workflow_run: dict[str, Any],
    latest_evidence: dict[str, Any],
    last_batch_input: str,
    hands_last_message: str,
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Infer workflow step progress from evidence, without enforcing step-by-step reporting.",
            "",
            "Goal:",
            "- Update MI's internal workflow cursor (best-effort): which steps are completed, and what the next step is.",
            "",
            "Constraints:",
            "- Do NOT ask the user questions.",
            "- Do NOT require Hands to follow a rigid protocol; Hands may complete multiple steps in one batch.",
            "- Only mark a step complete when evidence strongly implies it was completed.",
            "- You may mark multiple steps complete at once if Hands likely crossed them.",
            "- If you are uncertain, set should_update=false and keep next_step_id empty.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- completed_step_ids MUST be step ids from the provided workflow.steps list.",
            "- next_step_id MUST be a step id from the workflow.steps list, or empty when unknown/none.",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay (may include prior workflow_run state):",
            _to_json(project_overlay),
            "",
            "Thought DB context (canonical values/preferences; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Active workflow (MI IR):",
            _to_json(workflow),
            "",
            "Current workflow_run state (prior):",
            _to_json(workflow_run),
            "",
            "Latest evidence (from extract_evidence):",
            _to_json(latest_evidence),
            "",
            "Last batch input MI sent to Hands (verbatim):",
            (last_batch_input or "").strip(),
            "",
            "Hands last message (raw):",
            (hands_last_message or "").strip(),
            "",
            "Now output the workflow progress JSON.",
        ]
    ).strip() + "\n"


def checkpoint_decide_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    segment_evidence: list[dict[str, Any]],
    current_batch_id: str,
    planned_next_input: str,
    status_hint: str,
    notes: str,
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Decide whether to cut a 'segment checkpoint' after the current batch, and whether to mine workflows/preferences now.",
            "",
            "Definitions:",
            "- A segment is a coherent, potentially-repeatable chunk of work within a longer task.",
            "- A checkpoint is a boundary where it is safe/useful to summarize, mine a workflow, and reset the segment buffer.",
            "",
            "Constraints:",
            "- Prefer low user burden: do NOT introduce more user questions.",
            "- Do NOT enforce protocol tyranny; do not require rigid step-by-step reporting.",
            "- Only checkpoint when there is strong signal of subtask completion, phase change, or a clear boundary.",
            "- If the task is still in the middle of a single coherent flow, do NOT checkpoint.",
            "- If planned_next_input starts a new phase (e.g., 'now run tests', 'now refactor', 'now write docs'), consider checkpointing.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- If should_checkpoint=false, set checkpoint_kind=none and set should_mine_workflow/should_mine_preferences=false.",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (canonical values/preferences; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Segment evidence so far (most recent last):",
            _to_json(segment_evidence),
            "",
            f"Current batch_id: {current_batch_id}",
            f"Status hint: {status_hint}",
            "",
            "Planned next input to Hands (may be empty if stopping):",
            planned_next_input.strip(),
            "",
            "Run notes:",
            (notes or "").strip(),
            "",
            "Now output the checkpoint decision JSON.",
        ]
    ).strip() + "\n"


def suggest_workflow_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    recent_evidence: list[dict[str, Any]],
    notes: str,
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Suggest a reusable workflow IR only when it would significantly reduce user burden in future runs.",
            "",
            "Constraints:",
            "- MI sits above Hands and only controls input + reads output.",
            "- Do NOT enforce step-by-step protocol tyranny. Workflow steps should be coarse-grained and goal-oriented.",
            "- Only suggest a workflow when it is likely to repeat (or the benefit is extremely high).",
            "- Prefer project-scoped workflow suggestions by default (V1 solidification writes to the project store).",
            "- The workflow IR will be stored as MI source-of-truth; host workspace files are derived artifacts.",
            "- If you are not confident, set should_suggest=false and suggestion=null.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (canonical values/preferences; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Recent evidence (most recent last):",
            _to_json(recent_evidence),
            "",
            "Run notes:",
            (notes or "").strip(),
            "",
            "If you suggest a workflow:",
            "- Provide a stable signature string (used to count occurrences across runs).",
            "- Provide benefit=high ONLY when the user-burden reduction is substantial.",
            "- Provide a small number of steps (3-7). Each step MUST have an id.",
            "- Set workflow.enabled=false in the suggestion; MI decides whether to auto-enable.",
            "- Set workflow.id to an empty string.",
            "",
            "Now output the JSON.",
        ]
    ).strip() + "\n"


def mine_preferences_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    recent_evidence: list[dict[str, Any]],
    notes: str,
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Mine likely-stable user preferences/habits from MI-captured transcript/evidence.",
            "Output suggestions that MI can store as Thought DB preference/goal Claims (canonical), so future decisions do not depend on free-form learned text.",
            "",
            "Constraints:",
            "- Use ONLY the provided task + evidence (derived from MI-captured transcript) and any explicit user statements inside it.",
            "- Do NOT invent preferences. If unclear, suggest nothing.",
            "- Prefer project-scoped suggestions unless the preference is clearly global.",
            "- Keep suggestions low-burden: avoid rules that would cause MI to ask the user more often.",
            "- Do NOT enforce protocol tyranny; do not suggest rigid step-by-step reporting requirements.",
            "- Suggest at most a few high-signal preferences/goals; each should be actionable and unambiguous.",
            "- Avoid duplicating existing preference/goal Claims already present in the provided Thought DB context.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- Keep text short; write preference/goal guidance as imperative guidance (one sentence).",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (canonical values/preferences; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Recent evidence (most recent last):",
            _to_json(recent_evidence),
            "",
            "Run notes:",
            (notes or "").strip(),
            "",
            "Now output preference suggestions (or an empty list).",
        ]
    ).strip() + "\n"


def mine_claims_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    segment_evidence: list[dict[str, Any]],
    allowed_event_ids: list[str],
    min_confidence: float,
    max_claims: int,
    notes: str,
) -> str:
    allowed = [str(x) for x in allowed_event_ids if str(x).strip()]
    allowed = allowed[:200]
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Mine high-signal, reusable atomic Claims from MI-captured evidence.",
            "",
            "Claim definition:",
            "- A Claim is an atomic, reusable argument used to justify decisions/actions.",
            "- Claim types: fact / preference / assumption / goal.",
            "- Temporal semantics are first-class: MI will set asserted_ts; you may set valid_from/valid_to when known (otherwise null).",
            "",
            "Hard constraints:",
            "- Use ONLY the provided segment evidence (derived from MI-captured transcript/evidence).",
            "- Do NOT invent facts or preferences. If unclear, output no claims.",
            "- Each claim MUST cite 1-5 EvidenceLog event_id(s) from the allowed list.",
            "- Each claim MUST have a unique local_id (e.g., c1, c2). Edges MUST reference these local_id values.",
            f"- Output at most the top {int(max_claims)} claims; output fewer when unsure.",
            f"- Only output a claim when confidence >= {min_confidence:.2f}.",
            "- Prefer project-scoped claims unless clearly reusable across projects (then scope=global).",
            "- Avoid duplicating existing canonical preference/goal claims already present in Thought DB context; only output a claim when it adds durable value.",
            "- If you output edges: only connect claims in THIS output (use local_id), and cite source_event_ids from the allowed list.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- If no high-confidence reusable claims exist, output claims=[] and edges=[].",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (existing canonical claims; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Segment evidence (compact, most recent last):",
            _to_json(segment_evidence),
            "",
            "Allowed EvidenceLog event_id list (MUST cite only from here):",
            _to_json(allowed),
            "",
            "Thresholds:",
            f"- min_confidence: {min_confidence:.2f}",
            f"- max_claims: {int(max_claims)}",
            "",
            "Run notes:",
            (notes or "").strip(),
            "",
            "Now output mined claims (or empty lists).",
        ]
    ).strip() + "\n"


def learn_update_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    recent_learn_suggested: list[dict[str, Any]],
    existing_learned_claims: list[dict[str, Any]],
    allowed_event_ids: list[str],
    allowed_retract_claim_ids: list[str],
    min_confidence: float,
    max_claims: int,
    max_retracts: int,
    notes: str,
) -> str:
    allowed = [str(x) for x in (allowed_event_ids or []) if str(x).strip()][:80]
    retractable = [str(x) for x in (allowed_retract_claim_ids or []) if str(x).strip()][:400]
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Consolidate preference tightening suggestions into canonical Thought DB updates (append-only).",
            "",
            "Goal:",
            "- Reduce noise and drift: converge multiple per-batch learn_suggested items into a small canonical set.",
            "- Use explicit evolution edges (supersedes/same_as) and/or retractions when appropriate.",
            "",
            "Hard constraints:",
            "- Use ONLY the provided learn_suggested events and existing_learned_claims as input.",
            "- Every NEW claim MUST cite 1-5 EvidenceLog event_id(s) from the allowed list.",
            "- Every edge MUST cite 1-5 EvidenceLog event_id(s) from the allowed list.",
            "- Retractions are append-only: you may retract ONLY claim_ids in allowed_retract_claim_ids, and MUST cite allowed event_ids.",
            "- New learned claims MUST include the tag 'mi:learned'.",
            "- Prefer claim_type=preference or goal; avoid fact/assumption unless truly needed.",
            "- Keep it small: output at most the top few changes. (MI will enforce hard caps.)",
            "",
            "Guidance:",
            "- Prefer 'supersedes' when refining meaning/text; prefer 'same_as' for de-duplication.",
            "- Retract only when the claim is clearly wrong/obsolete/contradicted (high confidence).",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- patch.claims[*].local_id MUST be unique (e.g., c1, c2).",
            "- patch.edges may reference existing claim_id or a local_id (for new claims).",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Recent learn_suggested events (this run; compact):",
            _to_json(recent_learn_suggested if isinstance(recent_learn_suggested, list) else []),
            "",
            "Existing learned claims (active canonical; compact):",
            _to_json(existing_learned_claims if isinstance(existing_learned_claims, list) else []),
            "",
            "Allowed EvidenceLog event_id list (MUST cite only from here):",
            _to_json(allowed),
            "",
            "allowed_retract_claim_ids (ONLY retract from this list):",
            _to_json(retractable),
            "",
            "Thresholds (MI will enforce):",
            f"- min_confidence: {float(min_confidence):.2f}",
            f"- max_claims: {int(max_claims)}",
            f"- max_retracts: {int(max_retracts)}",
            "",
            "Run notes:",
            (notes or "").strip(),
            "",
            "Now output the learn_update JSON.",
        ]
    ).strip() + "\n"


def why_trace_prompt(
    *,
    target: dict[str, Any],
    as_of_ts: str,
    candidate_claims: list[dict[str, Any]],
    notes: str,
) -> str:
    ids = [
        str(c.get("claim_id") or "").strip()
        for c in (candidate_claims or [])
        if isinstance(c, dict) and str(c.get("claim_id") or "").strip()
    ]
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Perform root-cause tracing: select a minimal support set of atomic Claims that best explain a target decision/action/event.",
            "",
            "Rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- You MUST select claim ids ONLY from the provided candidate_claim_ids list.",
            "- Choose the MINIMAL set of claims that explains the target (usually 1-5).",
            "- Consider temporal validity: as_of_ts must fall within valid_from/valid_to when present; avoid out-of-window claims.",
            "- If insufficient evidence, set status=insufficient, chosen_claim_ids=[], and explain what's missing.",
            "",
            "as_of_ts:",
            (as_of_ts or "").strip(),
            "",
            "Target (verbatim JSON):",
            _to_json(target if isinstance(target, dict) else {}),
            "",
            "candidate_claim_ids (MUST choose only from here):",
            _to_json(ids),
            "",
            "Candidate claims (compact JSON):",
            _to_json(candidate_claims),
            "",
            "Run notes:",
            (notes or "").strip(),
            "",
            "Now output the WhyTrace JSON.",
        ]
    ).strip() + "\n"


def edit_workflow_prompt(
    *,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    workflow: dict[str, Any],
    user_request: str,
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation).",
            "Edit a stored workflow IR based on the user's natural-language request.",
            "",
            "Constraints:",
            "- Preserve workflow.id, workflow.version, and workflow.created_ts.",
            "- Make the smallest change that satisfies the request.",
            "- Keep step ids stable when possible; only add/remove steps when necessary.",
            "- Ensure every step has all required fields, even if empty strings.",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (canonical values/preferences; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Current workflow JSON:",
            _to_json(workflow),
            "",
            "User request:",
            (user_request or "").strip(),
            "",
            "Now output the edited workflow JSON + change_summary + conflicts + notes.",
        ]
    ).strip() + "\n"


def auto_answer_to_hands_prompt(
    *,
    task: str,
    hands_provider: str,
    mindspec_base: dict[str, Any],
    project_overlay: dict[str, Any],
    thought_db_context: dict[str, Any] | None,
    repo_observation: dict[str, Any],
    check_plan: dict[str, Any],
    recent_evidence: list[dict[str, Any]],
    hands_last_message: str,
) -> str:
    return "\n".join(
        [
            "You are MI (Mind Incarnation), operating above Hands.",
            "Your job: answer Hands' question(s) as the user when possible, using values/preferences + evidence + memory, to minimize user burden.",
            "",
            "Constraints:",
            "- MI sits above Hands and only controls input + reads output.",
            "- MI does NOT intercept or gate Hands tool execution.",
            "- MI does NOT force Hands into step-by-step protocols.",
            "- Do NOT ask the user to confirm completion; only ask when blocked by missing info or value conflicts.",
            "- MI is authorized to answer on behalf of the user (including when the user task says 'ask the user') using values/preferences and evidence.",
            "- If Hands asks for permission to do external actions (network/install/push/publish), decide using values/preferences; if not clearly covered, set needs_user_input=true.",
            "- If values/preferences clearly imply the answer (e.g., default-deny for network/install unless necessary), answer Hands directly without asking the user, unless evidence shows it is necessary and allowed.",
            "- If Hands asks what it should do next (e.g., 'what would you like me to do'), answer by restating the user task and any relevant constraints; do NOT ask the user.",
            "- If the last Hands message does not contain a question or request for user input, set should_answer=false and hands_answer_input=\"\".",
            "",
            "Output rules:",
            "- Output MUST be a single JSON object matching the provided JSON Schema.",
            "- No markdown, no extra keys, no extra commentary.",
            "- Keep hands_answer_input concise and directly actionable; only include what Hands needs to proceed.",
            "",
            "User task:",
            task.strip(),
            "",
            f"Hands provider: {hands_provider.strip() or '(unknown)'}",
            "",
            "Runtime config (structured):",
            _to_json(mindspec_base),
            "",
            "ProjectOverlay:",
            _to_json(project_overlay),
            "",
            "Thought DB context (canonical values/preferences; may be empty):",
            _to_json(thought_db_context if isinstance(thought_db_context, dict) else {}),
            "",
            "Repo observation (read-only heuristic):",
            _to_json(repo_observation),
            "",
            "Minimal check plan (from plan_min_checks):",
            _to_json(check_plan),
            "",
            "Recent evidence (most recent last):",
            _to_json(recent_evidence),
            "",
            "Hands last message (raw):",
            hands_last_message.strip(),
            "",
            "Now decide whether MI can answer Hands, and output the JSON.",
        ]
    ).strip() + "\n"
